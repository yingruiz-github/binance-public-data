{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read raw data downloaded from binance historical data api. Then combine them and convert them to paquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import psutil\n",
    "import shutil\n",
    "from python.yingruiz_config import KLINE_COLUMN_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage():\n",
    "    process = psutil.Process()\n",
    "    r = process.memory_info().rss / (1024 ** 3)\n",
    "    return r\n",
    "\n",
    "def read_kline_data(data_dir, header):\n",
    "    month_dir = Path(data_dir) / f\"spot/monthly/klines\"\n",
    "    day_dir = Path(data_dir) / f\"spot/daily/klines\" \n",
    "    \n",
    "    target_pairs_month = [path.name for path in month_dir.glob(\"*\")]\n",
    "    target_pairs_day = [path.name for path in day_dir.glob(\"*\")]\n",
    "    print(target_pairs_day)\n",
    "    assert set(target_pairs_month) == set(target_pairs_day)\n",
    "    \n",
    "    intervals = [interval.name for interval in (month_dir / target_pairs_month[0]).glob(\"*\")]\n",
    "    \n",
    "    data_dic = {}\n",
    "    for pair in target_pairs_month:\n",
    "        data_dic[pair] = {interval:None for interval in intervals}\n",
    "    \n",
    "    for pair in tqdm(data_dic):\n",
    "        for interval in data_dic[pair]:\n",
    "            temp_holder = []\n",
    "            for zip_file in (month_dir / pair / interval).glob(\"**/*.zip\"):\n",
    "                temp_holder.append(pd.read_csv(zip_file, header=None).values)\n",
    "            for zip_file in (day_dir / pair / interval).glob(\"**/*.zip\"):\n",
    "                temp_holder.append(pd.read_csv(zip_file, header =None).values)\n",
    "            temp = pd.DataFrame(np.concatenate(temp_holder))\n",
    "\n",
    "            temp.columns = header\n",
    "            data_dic[pair][interval] = temp\n",
    "            \n",
    "        \n",
    "        #print(memory_usage())\n",
    "        gc.collect()\n",
    "    return data_dic\n",
    "\n",
    "def read_data(data_dir, target, header):\n",
    "    # processs path\n",
    "    assert target in {\"aggTrades\", \"trades\"}, f\"valid targets are aggTrades, klines, trades\"\n",
    "    month_dir = Path(data_dir) / f\"spot/monthly/{target}\"\n",
    "    day_dir = Path(data_dir) / f\"spot/daily/{target}\" \n",
    "    \n",
    "    target_pairs_month = [path.name for path in month_dir.glob(\"*\")]\n",
    "    target_pairs_day = [path.name for path in day_dir.glob(\"*\")]\n",
    "    # print(target_pairs_day)\n",
    "    assert set(target_pairs_month) == set(target_pairs_day)    \n",
    "    \n",
    "    \n",
    "    target_pairs = target_pairs_month\n",
    "    data_dic = {}\n",
    "    for pair in target_pairs:\n",
    "        data_dic[pair] = None\n",
    "\n",
    "    for pair in tqdm(data_dic):\n",
    "        temp_holder = []\n",
    "        for zip_file in (month_dir / pair).glob(\"**/*.zip\"):\n",
    "            temp_holder.append(pd.read_csv(zip_file, header=None))\n",
    "            #gc.collect()\n",
    "            print(memory_usage(), zip_file)\n",
    "        for zip_file in (day_dir / pair).glob(\"**/*.zip\"):\n",
    "            temp_holder.append(pd.read_csv(zip_file, header =None))\n",
    "        temp = pd.concat(temp_holder, ignore_index=True)\n",
    "        \n",
    "        #print(count)\n",
    "        # return temp\n",
    "    \n",
    "        temp.columns = header\n",
    "        data_dic[pair] = temp\n",
    "        \n",
    "        # show this epoch memory usage\n",
    "        # print(memory_usage())\n",
    "        gc.collect()\n",
    "    return data_dic\n",
    "\n",
    "def read_trade_zip_and_store_to_arrow(data_dir, target, pair, header):\n",
    "    assert target in {\"aggTrades\", \"trades\"}, f\"valid targets are aggTrades, klines, trades\"\n",
    "    month_dir = Path(data_dir) / f\"spot/monthly/{target}\"\n",
    "    day_dir = Path(data_dir) / f\"spot/daily/{target}\" \n",
    "    \n",
    "    temp_holder = []\n",
    "    for zip_file in (month_dir / pair).glob(\"**/*.zip\"):\n",
    "        temp_holder.append(pd.read_csv(zip_file, header=None))\n",
    "        #gc.collect()\n",
    "        # print(memory_usage(), zip_file)\n",
    "    for zip_file in (day_dir / pair).glob(\"**/*.zip\"):\n",
    "        temp_holder.append(pd.read_csv(zip_file, header =None))\n",
    "    temp = pd.concat(temp_holder, ignore_index=True)\n",
    "\n",
    "    temp.columns = header\n",
    "    \n",
    "    new_save_dir = Path(\"/workspace/projects/binance-public-data/python/data/yingruiz_custom/klines\")\n",
    "    df = pa.Table.from_pandas(temp)\n",
    "    path = new_save_dir / f\"{pair}-{target}.parquet\"\n",
    "    pq.write_table(df, path)\n",
    "    \n",
    "    print(memory_usage(), shutil.disk_usage(\"/workspace\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/workspace/projects/binance-public-data/python/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read all of kline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kline_data = read_kline_data(data_dir=data_dir, header = KLINE_COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert readed kline data to paquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_paquet_wrapper(save_dir = Path(\"/workspace/projects/binance-public-data/python/data/yingruiz_custom/klines\"), kline_data = kline_data):\n",
    "    # safe check\n",
    "    previous = None \n",
    "    for pair in kline_data:\n",
    "        if previous == None:\n",
    "            previous = set(kline_data[pair].keys())\n",
    "        assert previous == set(kline_data[pair].keys()), f\"detect pair {pair} has a different intervals {kline_data[pair].keys()}\"\n",
    "        \n",
    "    for pair in kline_data:\n",
    "        for interval in kline_data[pair]:\n",
    "            table = pa.Table.from_pandas(kline_data[pair][interval])\n",
    "            path = save_dir / f\"{pair}-{interval}-klines.parquet\"\n",
    "            pq.write_table(table, path)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_paquet_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trade_zip_and_store_to_arrow(data_dir, target, pair, header):\n",
    "    assert target in {\"aggTrades\", \"trades\"}, f\"valid targets are aggTrades, klines, trades\"\n",
    "    month_dir = Path(data_dir) / f\"spot/monthly/{target}\"\n",
    "    day_dir = Path(data_dir) / f\"spot/daily/{target}\" \n",
    "    \n",
    "    temp_holder = []\n",
    "    for zip_file in (month_dir / pair).glob(\"**/*.zip\"):\n",
    "        temp_holder.append(pd.read_csv(zip_file, header=None))\n",
    "        #gc.collect()\n",
    "        # print(memory_usage(), zip_file)\n",
    "    for zip_file in (day_dir / pair).glob(\"**/*.zip\"):\n",
    "        temp_holder.append(pd.read_csv(zip_file, header =None))\n",
    "    temp = pd.concat(temp_holder, ignore_index=True)\n",
    "\n",
    "    temp.columns = header\n",
    "    \n",
    "    new_save_dir = Path(\"/workspace/projects/binance-public-data/python/data/yingruiz_custom/klines\")\n",
    "    df = pa.Table.from_pandas(temp)\n",
    "    path = new_save_dir / f\"{pair}-{target}.parquet\"\n",
    "    pq.write_table(df, path)\n",
    "    \n",
    "    print(memory_usage(), shutil.disk_usage(\"/workspace\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto_trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
